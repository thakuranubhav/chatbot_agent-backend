AI Chatbot Backend (FastAPI + LangChain)

An AI-powered conversational backend built using FastAPI and LangChain, supporting multi-threaded conversations with persistent memory handling.

This backend is designed to be production-ready and deployable on Render, with clean API design and scalable architecture.

ğŸ“Œ Features

ğŸ§  LLM-powered chatbot (LangChain integration)

ğŸ—‚ Multi-threaded conversation support

ğŸ’¬ Persistent thread-based chat history

ğŸ” Streaming response handling

ğŸŒ CORS enabled (Frontend ready)

ğŸ¥ Health check endpoint

ğŸ“„ Auto-generated Swagger Docs (/docs)

â˜ï¸ Deployable on Render

ğŸ— Tech Stack

Backend: FastAPI

LLM Orchestration: LangChain

Server: Uvicorn

Data Validation: Pydantic

Deployment: Render

Language: Python 3.10+